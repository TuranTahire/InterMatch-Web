# matching_engine.py
# RAG Destekli Uzman Analiz Sistemi

import os
import glob
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from groq import Groq
from dotenv import load_dotenv

load_dotenv('config.env')

def build_vectorstore():
    """
    Documents klasÃ¶rÃ¼ndeki tÃ¼m belgeleri yÃ¼kleyip ChromaDB'ye ekler
    """
    print("ğŸ“ UZMAN EÄÄ°TÄ°M PROGRAMI BAÅLIYOR...")
    print("=" * 50)

    try:
        # 1. Embedding modelini hazÄ±rla
        print("ğŸ” Embedding modeli hazÄ±rlanÄ±yor...")
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        print("âœ… Embedding modeli hazÄ±r.")

        # 2. Documents klasÃ¶rÃ¼ndeki belgeleri yÃ¼kle
        print("\nğŸ“š Belgeler yÃ¼kleniyor...")
        documents = []
        txt_files = glob.glob('documents/*.txt')

        for file_path in txt_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                    filename = os.path.basename(file_path)
                    doc = Document(page_content=content, metadata={"source": filename})
                    documents.append(doc)
                    print(f"âœ… {filename} yÃ¼klendi")
            except Exception as e:
                print(f"âŒ {file_path} yÃ¼klenirken hata: {e}")

        print(f"âœ… {len(documents)} adet belge yÃ¼klendi.")

        # 3. Belgeleri chunk'lara bÃ¶l
        print("\nâœ‚ï¸ Belgeler kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼nÃ¼yor...")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
        texts = text_splitter.split_documents(documents)
        print(f"âœ… Belgeler {len(texts)} adet parÃ§aya bÃ¶lÃ¼ndÃ¼.")

        # 4. ChromaDB'ye ekle
        print("\nğŸ§  VektÃ¶r veritabanÄ±na kaydediliyor...")
        vectordb = Chroma.from_documents(
            documents=texts,
            embedding=embeddings,
            persist_directory="./chroma_db"
        )
        
        print("\n" + "=" * 50)
        print("ğŸ‰ UZMAN EÄÄ°TÄ°MÄ° TAMAMLANDI!")
        print(f"ğŸ§  VektÃ¶r veritabanÄ± '{len(texts)}' adet parÃ§a ile oluÅŸturuldu.")
        print("=" * 50)
        
        return vectordb
        
    except Exception as e:
        print(f"âŒ VektÃ¶r veritabanÄ± oluÅŸturma hatasÄ±: {e}")
        return None

def calculate_cosine_similarity(vec1, vec2):
    """
    Ä°ki embedding vektÃ¶rÃ¼ arasÄ±ndaki cosine similarity deÄŸerini hesaplar
    
    Args:
        vec1: Ä°lk embedding vektÃ¶rÃ¼
        vec2: Ä°kinci embedding vektÃ¶rÃ¼
        
    Returns:
        Cosine similarity skoru (0-1 arasÄ±)
    """
    try:
        # VektÃ¶rleri numpy array'e Ã§evir
        vec1_array = np.array(vec1).reshape(1, -1)
        vec2_array = np.array(vec2).reshape(1, -1)
        
        # Cosine similarity hesapla
        similarity = cosine_similarity(vec1_array, vec2_array)[0][0]
        
        return float(similarity)
    except Exception as e:
        print(f"âŒ Cosine similarity hesaplama hatasÄ±: {e}")
        return 0.0

def extract_skills(text):
    """
    Metinden becerileri Ã§Ä±karÄ±r
    
    Args:
        text: Metin
        
    Returns:
        Beceri listesi
    """
    # Basit beceri Ã§Ä±karma (gerÃ§ek uygulamada daha geliÅŸmiÅŸ NLP kullanÄ±labilir)
    common_skills = [
        'python', 'java', 'javascript', 'react', 'node.js', 'sql', 'mongodb',
        'docker', 'kubernetes', 'aws', 'azure', 'git', 'agile', 'scrum',
        'machine learning', 'ai', 'data science', 'analytics', 'project management',
        'leadership', 'communication', 'teamwork', 'problem solving', 'analytical thinking'
    ]
    
    text_lower = text.lower()
    found_skills = []
    
    for skill in common_skills:
        if skill in text_lower:
            found_skills.append(skill)
    
    return found_skills

def calculate_skill_match(cv_skills, job_skills):
    """
    CV ve iÅŸ ilanÄ± becerileri arasÄ±ndaki uyumu hesaplar
    
    Args:
        cv_skills: CV'deki beceriler listesi
        job_skills: Ä°ÅŸ ilanÄ±ndaki beceriler listesi
        
    Returns:
        Beceri uyum skoru (0-1 arasÄ±)
    """
    try:
        if not job_skills:
            return 0.5  # Beceri belirtilmemiÅŸse orta skor
        
        # Ortak becerileri bul
        common_skills = set(cv_skills) & set(job_skills)
        
        # Uyum skorunu hesapla
        if len(job_skills) > 0:
            skill_match = len(common_skills) / len(job_skills)
        else:
            skill_match = 0.0
        
        return min(skill_match, 1.0)  # 1.0'Ä± geÃ§memesi iÃ§in
        
    except Exception as e:
        print(f"âŒ Beceri uyum hesaplama hatasÄ±: {e}")
        return 0.0

def calculate_final_score(cv_text, job_text, rag_context=""):
    """
    CV ve iÅŸ ilanÄ± arasÄ±ndaki final skoru hesaplar
    
    Args:
        cv_text: CV metni
        job_text: Ä°ÅŸ ilanÄ± metni
        rag_context: RAG'den gelen ek baÄŸlam
        
    Returns:
        Final skor (0-100 arasÄ±) ve detaylar
    """
    try:
        print("ğŸ¯ SKOR HESAPLAMA BAÅLIYOR...")
        
        # 1. Embedding modelini hazÄ±rla
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        
        # 2. CV ve iÅŸ ilanÄ± embedding'lerini hesapla
        print("ğŸ” Embedding'ler hesaplanÄ±yor...")
        cv_embedding = embeddings.embed_query(cv_text)
        job_embedding = embeddings.embed_query(job_text)
        
        # 3. Cosine similarity hesapla
        print("ğŸ“Š Cosine similarity hesaplanÄ±yor...")
        text_similarity = calculate_cosine_similarity(cv_embedding, job_embedding)
        text_score = text_similarity * 100  # 0-100 arasÄ±na Ã§evir
        
        # 4. Becerileri Ã§Ä±kar ve karÅŸÄ±laÅŸtÄ±r
        print("ğŸ› ï¸ Beceriler analiz ediliyor...")
        cv_skills = extract_skills(cv_text)
        job_skills = extract_skills(job_text)
        skill_match = calculate_skill_match(cv_skills, job_skills)
        skill_score = skill_match * 100  # 0-100 arasÄ±na Ã§evir
        
        # 5. RAG baÄŸlamÄ±ndan ek puan (varsa)
        rag_bonus = 0
        if rag_context:
            print("ğŸ§  RAG baÄŸlamÄ± analiz ediliyor...")
            # RAG baÄŸlamÄ±ndan beceri Ã§Ä±kar
            rag_skills = extract_skills(rag_context)
            rag_skill_match = calculate_skill_match(cv_skills, rag_skills)
            rag_bonus = rag_skill_match * 10  # 0-10 arasÄ± bonus
        
        # 6. Final skoru hesapla
        final_score = (text_score + skill_score + rag_bonus) / 2
        final_score = min(final_score, 100)  # 100'Ã¼ geÃ§memesi iÃ§in
        
        # 7. SonuÃ§larÄ± hazÄ±rla
        result = {
            "final_score": round(final_score, 1),
            "text_similarity": round(text_score, 1),
            "skill_match": round(skill_score, 1),
            "rag_bonus": round(rag_bonus, 1),
            "cv_skills": cv_skills,
            "job_skills": job_skills,
            "common_skills": list(set(cv_skills) & set(job_skills)),
            "missing_skills": list(set(job_skills) - set(cv_skills))
        }
        
        print(f"âœ… Skor hesaplama tamamlandÄ±: {final_score:.1f}/100")
        return result
        
    except Exception as e:
        print(f"âŒ Skor hesaplama hatasÄ±: {e}")
        return {
            "final_score": 0,
            "text_similarity": 0,
            "skill_match": 0,
            "rag_bonus": 0,
            "cv_skills": [],
            "job_skills": [],
            "common_skills": [],
            "missing_skills": [],
            "error": str(e)
        }

def get_rag_analysis(cv_text, job_text):
    """
    RAG destekli uzman analizi yapar
    UzmanÄ±n beynindeki bilgileri kullanarak CV ve iÅŸ ilanÄ± analizi yapar
    """
    print("--- RAG Destekli Uzman Analizi BaÅŸlatÄ±lÄ±yor ---")

    try:
        # 1. UzmanÄ±n "gÃ¶zlÃ¼ÄŸÃ¼nÃ¼" ve "beynini" hazÄ±rla
        print("ğŸ” UzmanÄ±n gÃ¶zlÃ¼ÄŸÃ¼ ve beyni hazÄ±rlanÄ±yor...")
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectordb = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
        print("âœ… UzmanÄ±n beyni yÃ¼klendi.")

        # 2. Beyinden konuyla ilgili notlarÄ± bul ve getir
        print("ğŸ§  UzmanÄ±n beyninden ilgili notlar aranÄ±yor...")
        query = f"CV analizi ve iÅŸ ilanÄ±: {job_text[:200]}..."  # Ä°lana gÃ¶re en alakalÄ± notlarÄ± bul
        relevant_docs = vectordb.similarity_search(query, k=3)  # En alakalÄ± 3 notu getir
        context = "\n\n".join(doc.page_content for doc in relevant_docs)
        print(f"âœ… UzmanÄ±n beyninden {len(relevant_docs)} adet ilgili not bulundu.")

        # 3. Uzmana sorulacak soruyu hazÄ±rla (notlarÄ± da ekleyerek)
        enhanced_prompt = f"""
        Sen bir uzman kariyer danÄ±ÅŸmanÄ±sÄ±n. CevaplarÄ±nÄ± SANA VERÄ°LEN UZMAN NOTLARI'na dayandÄ±rarak oluÅŸtur.

        ---
        UZMAN NOTLARI:
        {context}
        ---

        GÃ–REV: YukarÄ±daki uzman notlarÄ± Ä±ÅŸÄ±ÄŸÄ±nda, aÅŸaÄŸÄ±daki CV ve iÅŸ ilanÄ±nÄ± detaylÄ±ca analiz et.

        CV METNÄ°:
        {cv_text}

        Ä°Å Ä°LANI METNÄ°:
        {job_text}

        Analizini ÅŸu formatta, baÅŸlÄ±klarÄ± kullanarak ve TÃ¼rkÃ§e olarak sunmalÄ±sÄ±n:

        **Uyum Skoru:** [CV'nin ilana ne kadar uygun olduÄŸunu 100 Ã¼zerinden bir yÃ¼zde olarak belirt]

        **Ã–zet DeÄŸerlendirme:** [AdayÄ±n bu pozisyon iÃ§in neden uygun veya uygun olmadÄ±ÄŸÄ±nÄ± 2-3 cÃ¼mlelik kÄ±sa bir paragrafta aÃ§Ä±kla]

        **EÅŸleÅŸen Anahtar Kelimeler ve Yetenekler:** [CV'de bulunan ve ilanda da istenen en Ã¶nemli 3-5 yetenek veya anahtar kelimeyi madde madde listele]

        **Eksik veya GeliÅŸtirilmesi Gereken YÃ¶nler:** [Ä°landa aranan ancak CV'de belirgin olmayan veya eksik olan 2-3 Ã¶nemli noktayÄ± madde madde belirt]

        **Uzman Tavsiyeleri:** [YukarÄ±daki uzman notlarÄ±na dayanarak, adaya Ã¶zel tavsiyeler ver]

        **CV Ä°yileÅŸtirme Ã–nerileri:** [Uzman notlarÄ±na gÃ¶re CV'yi nasÄ±l iyileÅŸtirebileceÄŸini belirt]
        """

        # 4. Skor hesaplama
        print("ğŸ¯ Skor hesaplama baÅŸlatÄ±lÄ±yor...")
        score_result = calculate_final_score(cv_text, job_text, context)
        
        # 5. Uzmandan cevap al (Groq)
        print("ğŸ¤– Uzman analizi yapÄ±lÄ±yor...")
        client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": enhanced_prompt}],
            model="llama3-8b-8192"
        )
        
        ai_analysis = chat_completion.choices[0].message.content
        
        # 6. SonuÃ§larÄ± birleÅŸtir
        result = {
            "analysis": ai_analysis,
            "score": score_result,
            "rag_context_used": len(relevant_docs)
        }
        
        print("âœ… RAG destekli uzman analizi ve skor hesaplama tamamlandÄ±.")
        return result
        
    except Exception as e:
        print(f"âŒ RAG Analiz hatasÄ±: {e}")
        return f"RAG analizi sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}"

def get_rag_interview_questions(cv_text, job_text):
    """
    RAG destekli mÃ¼lakat sorularÄ± Ã¼retir
    """
    print("--- RAG Destekli MÃ¼lakat SorularÄ± Ãœretiliyor ---")

    try:
        # 1. UzmanÄ±n beynini hazÄ±rla
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectordb = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)

        # 2. MÃ¼lakat konularÄ±yla ilgili notlarÄ± bul
        query = f"MÃ¼lakat sorularÄ± ve teknik sorular: {job_text[:200]}..."
        relevant_docs = vectordb.similarity_search(query, k=2)
        context = "\n\n".join(doc.page_content for doc in relevant_docs)

        # 3. MÃ¼lakat sorularÄ± prompt'u hazÄ±rla
        enhanced_prompt = f"""
        Sen bir uzman mÃ¼lakatÃ§Ä±sÄ±n. AÅŸaÄŸÄ±daki uzman notlarÄ±nÄ± kullanarak mÃ¼lakat sorularÄ± Ã¼retmelisin.

        ---
        UZMAN NOTLARI:
        {context}
        ---

        GÃ–REV: YukarÄ±daki uzman notlarÄ± Ä±ÅŸÄ±ÄŸÄ±nda, aÅŸaÄŸÄ±daki CV ve iÅŸ ilanÄ±na gÃ¶re mÃ¼lakat sorularÄ± Ã¼ret.

        CV METNÄ°:
        {cv_text}

        Ä°Å Ä°LANI METNÄ°:
        {job_text}

        AÅŸaÄŸÄ±daki kategorilerde sorular Ã¼ret:

        **Teknik Sorular (3-5 soru):**
        [Pozisyonla ilgili teknik bilgi ve becerileri test eden sorular]

        **Behavioral Sorular (3-5 soru):**
        [GeÃ§miÅŸ deneyimleri ve davranÄ±ÅŸlarÄ± test eden sorular]

        **Durumsal Sorular (2-3 soru):**
        [Ä°ÅŸ ortamÄ±nda karÅŸÄ±laÅŸabileceÄŸi durumlarÄ± test eden sorular]

        **Uzman Ä°puÃ§larÄ±:**
        [YukarÄ±daki uzman notlarÄ±na dayanarak, mÃ¼lakat iÃ§in Ã¶zel ipuÃ§larÄ±]
        """

        # 4. SorularÄ± Ã¼ret
        client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": enhanced_prompt}],
            model="llama3-8b-8192"
        )
        
        return chat_completion.choices[0].message.content
        
    except Exception as e:
        print(f"âŒ RAG MÃ¼lakat sorularÄ± hatasÄ±: {e}")
        return f"MÃ¼lakat sorularÄ± Ã¼retilirken bir hata oluÅŸtu: {str(e)}"

def get_rag_cv_improvements(cv_text, job_text):
    """
    RAG destekli CV iyileÅŸtirme Ã¶nerileri Ã¼retir
    """
    print("--- RAG Destekli CV Ä°yileÅŸtirme Ã–nerileri Ãœretiliyor ---")

    try:
        # 1. UzmanÄ±n beynini hazÄ±rla
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectordb = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)

        # 2. CV iyileÅŸtirme konularÄ±yla ilgili notlarÄ± bul
        query = f"CV yazma ipuÃ§larÄ± ve iyileÅŸtirme: {job_text[:200]}..."
        relevant_docs = vectordb.similarity_search(query, k=2)
        context = "\n\n".join(doc.page_content for doc in relevant_docs)

        # 3. CV iyileÅŸtirme prompt'u hazÄ±rla
        enhanced_prompt = f"""
        Sen bir uzman CV danÄ±ÅŸmanÄ±sÄ±n. AÅŸaÄŸÄ±daki uzman notlarÄ±nÄ± kullanarak CV iyileÅŸtirme Ã¶nerileri Ã¼retmelisin.

        ---
        UZMAN NOTLARI:
        {context}
        ---

        GÃ–REV: YukarÄ±daki uzman notlarÄ± Ä±ÅŸÄ±ÄŸÄ±nda, aÅŸaÄŸÄ±daki CV'yi iÅŸ ilanÄ±na gÃ¶re iyileÅŸtirme Ã¶nerileri ver.

        CV METNÄ°:
        {cv_text}

        Ä°Å Ä°LANI METNÄ°:
        {job_text}

        AÅŸaÄŸÄ±daki kategorilerde Ã¶neriler Ã¼ret:

        **YapÄ±sal Ä°yileÅŸtirmeler:**
        [CV'nin genel yapÄ±sÄ± ve formatÄ± iÃ§in Ã¶neriler]

        **Ä°Ã§erik Ä°yileÅŸtirmeleri:**
        [CV iÃ§eriÄŸini gÃ¼Ã§lendirmek iÃ§in Ã¶neriler]

        **Anahtar Kelime Optimizasyonu:**
        [ATS sistemleri iÃ§in anahtar kelime Ã¶nerileri]

        **Deneyim Vurgulama:**
        [Deneyimleri daha etkili sunmak iÃ§in Ã¶neriler]

        **Beceri GeliÅŸtirme:**
        [Eksik becerileri geliÅŸtirmek iÃ§in Ã¶neriler]

        **Uzman Tavsiyeleri:**
        [YukarÄ±daki uzman notlarÄ±na dayanarak Ã¶zel tavsiyeler]
        """

        # 4. Ã–nerileri Ã¼ret
        client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": enhanced_prompt}],
            model="llama3-8b-8192"
        )
        
        return chat_completion.choices[0].message.content
        
    except Exception as e:
        print(f"âŒ RAG CV iyileÅŸtirme hatasÄ±: {e}")
        return f"CV iyileÅŸtirme Ã¶nerileri Ã¼retilirken bir hata oluÅŸtu: {str(e)}"
